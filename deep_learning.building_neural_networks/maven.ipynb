{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yoga: Maven (Deep Neural Networks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    ">\n",
    "> - Explore the effects of data on model performance\n",
    "> - Experiment with training regimes\n",
    "> - Experiment with model architectures\n",
    "\n",
    "<small>🚫🤖 AI code generation is NOT recommended for this notebook.</small>\n",
    "\n",
    "<small>🙋 Have a suggestion for how to improve this file? Please open an issue for [this repo on GitHub](https://github.com/orgs/deepatlasai/repositories). Create a Help Desk ticket in Discord for time-sensitive technical issues.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deep Atlas Exercise Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Ensure you are using the coursework Pipenv environment and kernel ([instructions](../SETUP.md))\n",
    "- [ ] Apply the standard Deep Atlas environment setup process by running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join('..', 'includes'))\n",
    "import deep_atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚦 Checkpoint: Start\n",
    "\n",
    "- [ ] Run this cell to record your start time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2025-05-08T14:48:40.282964\n",
      "🚀 Success! Get started...\n"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your new deep learning knowhow to adapt your MNIST training workflow to work for [Fashion -MNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html). \n",
    "\n",
    "Fashion-MNIST contains a set of images processed like MNIST: 70,000 28×28px grayscale images representing 10 classes. \n",
    "\n",
    "How does the architecture designed for MNIST perform when trained for Fashion-MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevincorstorphine/.local/share/virtualenvs/mli-2025-05-05-coursework-rNXVWyyx/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:03<00:00, 7559704.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/Fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 179747.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/Fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3058000.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/Fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 18990569.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/Fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./downloads/Fashionmnist/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "trainset = datasets.FashionMNIST(\n",
    "    \"./downloads/Fashionmnist\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    \"./downloads/Fashionmnist\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=test_batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to run on: GPU, MPS, or CPU\n",
    "device = torch.device(\n",
    "    \"cpu\"\n",
    "    # if torch.cuda.is_available()\n",
    "    # else \"mps\"\n",
    "    # if torch.backends.mps.is_available()\n",
    "    # else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cpu and saved to ./downloads/Fashionmnist.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleNN                                 [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 10]                  --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
       "│    └─Conv2d: 2-4                       [64, 64, 14, 14]          18,496\n",
       "│    └─ReLU: 2-5                         [64, 64, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-6                    [64, 64, 7, 7]            --\n",
       "│    └─Conv2d: 2-7                       [64, 128, 7, 7]           73,856\n",
       "│    └─ReLU: 2-8                         [64, 128, 7, 7]           --\n",
       "│    └─MaxPool2d: 2-9                    [64, 128, 3, 3]           --\n",
       "│    └─Flatten: 2-10                     [64, 1152]                --\n",
       "│    └─Linear: 2-11                      [64, 512]                 590,336\n",
       "│    └─ReLU: 2-12                        [64, 512]                 --\n",
       "│    └─Linear: 2-13                      [64, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 688,138\n",
       "Trainable params: 688,138\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 517.79\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 22.75\n",
       "Params size (MB): 2.75\n",
       "Estimated Total Size (MB): 25.70\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # Move flatten here after conv layers\n",
    "            nn.Linear(128 * 3 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Create model instance\n",
    "model = SimpleNN()\n",
    "# Move model to device if available, otherwise keep on CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move model to device and save it\n",
    "model = model.to(device)\n",
    "torch.save(model, \"./downloads/Fashionmnist.pth\")\n",
    "print(f\"Model moved to {device} and saved to ./downloads/Fashionmnist.pth\")\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size=(train_batch_size, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1 = torch.load(\"./downloads/Fashionmnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_v1 on test data: 9.43%\n"
     ]
    }
   ],
   "source": [
    "model_v1.eval()\n",
    "\n",
    "correct = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        # Remove the flattening of images since model expects 4D input\n",
    "        images = images.to(device)\n",
    "        outputs = model_v1(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # compute the accuracy of the model\n",
    "        correct += (predicted == labels.to(device)).sum().item() / labels.shape[0]\n",
    "\n",
    "\n",
    "print(f\"Accuracy of model_v1 on test data: {100 * correct / len(testloader):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a single model on both sets\n",
    "\n",
    "Is it possible for a single neural network to learn how to classify images for MNIST and Fashion-MNIST? \n",
    "\n",
    "Try training a single model with the following constraints: \n",
    "\n",
    "- Train the model on MNIST and Fashion-MNIST training sets.\n",
    "- Retain the same number of output classes (both datasets have 10 possible classes).\n",
    "- Try adjusting the size of the layers and track the effects of the changes on model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact and metrics logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you work, make sure to document your modeling experiments by logging your inputs (code, data, parameter values) and outputs (models, metrics).  \n",
    "* You can use Weights and Biases or any other system of your choice, but try to log enough information that a classmate could understand and reproduce your modeling experiments by viewing only your logs, not your notebook.\n",
    "\n",
    "From now on, you should document all your modeling experiments, even if we don't remind you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_one_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# During training, log metrics\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     train_loss = \u001b[43mtrain_one_epoch\u001b[49m(model_v1, trainloader, criterion, optimizer)\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Validation loop\u001b[39;00m\n\u001b[32m     26\u001b[39m     val_loss, val_acc = validate(model_v1, valloader, criterion)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_one_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "losses = []\n",
    "epochs = 10\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"mnist-fashion-mnist-classification\",\n",
    "    config={\n",
    "        \"architecture\": \"SimpleNN\",\n",
    "        \"dataset\": \"MNIST + Fashion-MNIST\",\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"optimizer\": \"Adam\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Log model architecture\n",
    "wandb.watch(model_v1)\n",
    "\n",
    "# During training, log metrics\n",
    "for epoch in range(epochs):\n",
    "    # Training loop\n",
    "    train_loss = train_one_epoch(model_v1, trainloader, criterion, optimizer)\n",
    "    \n",
    "    # Validation loop\n",
    "    val_loss, val_acc = validate(model_v1, valloader, criterion)\n",
    "    \n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "# Log final test accuracy\n",
    "wandb.log({\"test_accuracy\": 100 * correct / len(testloader)})\n",
    "\n",
    "# Save model artifact\n",
    "wandb.save(\"model_v1.pth\")\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚦 Checkpoint: Stop\n",
    "\n",
    "- [ ] Uncomment this code\n",
    "- [ ] Complete the feedback form\n",
    "- [ ] Run the cell to log your responses and record your stop time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Feedback logged!\n",
      "Stopped at: 2025-05-08T15:42:44.244821\n",
      "🎉 Thanks! You're all done.\n"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_feedback(\n",
    "    {\n",
    "        # How long were you actively focused on this section? (HH:MM)\n",
    "        \"active_time\": \"Still going over it\",\n",
    "        # Did you feel finished with this section (Yes/No):\n",
    "        \"finished\": \"not really, I need to go back over a lot.\",\n",
    "        # How much did you enjoy this section? (1–5)\n",
    "        \"enjoyment\": \"It was fun\",\n",
    "        # How useful was this section? (1–5)\n",
    "        \"usefulness\": \"4\",\n",
    "        # Did you skip any steps?\n",
    "        \"skipped_steps\": \"I made a crappy model for fashion, couldn't get it to work well and haven't made the second yet\",\n",
    "        # Any obvious opportunities for improvement?\n",
    "        \"suggestions\": \"I apparently have many opportunites for improvement here lol\",\n",
    "    }\n",
    ")\n",
    "deep_atlas.log_stop_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You did it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mli-2025-05-05-coursework-rNXVWyyx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
