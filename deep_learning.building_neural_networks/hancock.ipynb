{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Hancock (Deep Neural Networks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#pytorch` `#deep-learning` `#classification` `#linear` `#activation` `#export` `#mnist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    ">\n",
    "> - Design and instantiate a deep neural network model using the PyTorch framework.\n",
    "> - Train the model to optically identify handwritten digits, using the MNIST dataset.\n",
    "> - Verify the accuracy of the model and run inference.\n",
    "\n",
    "<small>üö´ü§ñ AI code generation is not recommended for this notebook.</small>\n",
    "\n",
    "<small>üôã Have a suggestion for how to improve this file? Please open an issue for [this repo on GitHub](https://github.com/orgs/deepatlasai/repositories). Create a Help Desk ticket in Discord for time-sensitive technical issues.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deep Atlas Exercise Set Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Ensure you are using the coursework Pipenv environment and kernel ([instructions](../SETUP.md))\n",
    "- [ ] Apply the standard Deep Atlas environment setup process by running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Running in a unrecognized environment.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join('..', 'includes'))\n",
    "\n",
    "import deep_atlas\n",
    "from deep_atlas import FILL_THIS_IN\n",
    "deep_atlas.initialize_environment()\n",
    "if deep_atlas.environment == 'COLAB':\n",
    "    %pip install -q python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö¶ Checkpoint: Start\n",
    "\n",
    "- [ ] Run this cell to record your start time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2025-05-07T17:28:21.838573\n",
      "üöÄ Success! Get started...\n"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2025-05-07T15:58:34.771069\n",
      "üöÄ Success! Get started...\n"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Networks are able to model arbitrary functions and learn probabilities using thousands (even billions) of parameters (weights and biases).\n",
    "\n",
    "> For a full review of the theory of how Deep Learning Neural Nets work, refer to Deep Learning section of Precourse.\n",
    "\n",
    "PyTorch is a popular framework for defining neural networks in Python. Code you write is compiled into optimized machine code, which ‚Äî depending on available hardware ‚Äî will even be optimized to run on GPUs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mCourtesy Notice\u001b[0m:\n",
      "Pipenv found itself running within a virtual environment,  so it will \n",
      "automatically use that environment, instead of  creating its own for any \n",
      "project. You can set\n",
      "\u001b[1;33mPIPENV_IGNORE_VIRTUALENVS\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m1\u001b[0m to force pipenv to ignore that environment and \n",
      "create  its own instead.\n",
      "You can set \u001b[1;33mPIPENV_VERBOSITY\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m-1\u001b[0m to suppress this warning.\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1;32mInstalling ipykernel==6.28.0...\u001b[0m\n",
      "‚úî Installation Succeeded\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(0d7d2d)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1;32mUpgrading\u001b[0m \u001b[33mipykernel\u001b[0m==\u001b[1;36m6.28\u001b[0m.\u001b[1;36m0\u001b[0m in \u001b[39m dependencies.\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K‚úî Success! Locking packages...\n",
      "\u001b[2K\u001b[32m‚†π\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K‚úî Success! Locking packages...\n",
      "\u001b[2K\u001b[32m‚†á\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KTo activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(0d7d2d)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(0d7d2d)...\u001b[0m\n",
      "\u001b[32mCourtesy Notice\u001b[0m:\n",
      "Pipenv found itself running within a virtual environment,  so it will \n",
      "automatically use that environment, instead of  creating its own for any \n",
      "project. You can set\n",
      "\u001b[1;33mPIPENV_IGNORE_VIRTUALENVS\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m1\u001b[0m to force pipenv to ignore that environment and \n",
      "create  its own instead.\n",
      "You can set \u001b[1;33mPIPENV_VERBOSITY\u001b[0m\u001b[1m=\u001b[0m\u001b[1;36m-1\u001b[0m to suppress this warning.\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1;32mInstalling matplotlib==3.8...\u001b[0m\n",
      "‚úî Installation Succeeded\n",
      "\u001b[1;32mInstalling torch==2.1.2...\u001b[0m\n",
      "‚úî Installation Succeeded\n",
      "\u001b[1;32mInstalling torchvision==0.16.2...\u001b[0m\n",
      "‚úî Installation Succeeded\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(0d7d2d)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1;32mUpgrading\u001b[0m \u001b[33mmatplotlib\u001b[0m==\u001b[1;36m3.8\u001b[0m, \u001b[33mtorch\u001b[0m==\u001b[1;36m2.1\u001b[0m.\u001b[1;36m2\u001b[0m, \u001b[33mtorchvision\u001b[0m==\u001b[1;36m0.16\u001b[0m.\u001b[1;36m2\u001b[0m in \u001b[39m dependencies.\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K‚úî Success! Locking packages...\n",
      "\u001b[2K\u001b[32m‚†ß\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K‚úî Success! Locking packages...\n",
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KTo activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(0d7d2d)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(0d7d2d)...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if deep_atlas.environment == 'VIRTUAL':\n",
    "    !pipenv install ipykernel==6.28.0\n",
    "    !pipenv install matplotlib==3.8 torch==2.1.2 torchvision==0.16.2\n",
    "if deep_atlas.environment == 'COLAB':\n",
    "    %pip install matplotlib==3.8.2 torch==2.1.2 torchvision==0.16.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevincorstorphine/.local/share/virtualenvs/mli-2025-05-05-coursework-rNXVWyyx/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # (i.e. \"neural network\")\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2025-05-07T17:28:21.838573\n",
      "üöÄ Success! Get started...\n"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download and process our dataset for this exercise: MNIST\n",
    "\n",
    "- A popular dataset of handwritten digits, 0‚Äì9, resized to 28√ó28px and made black and white\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "\n",
    "We can download the dataset from Pytorch's TorchVision library (imported above). TorchVision maintains links to a few [popular datasets](https://pytorch.org/vision/stable/datasets.html), including MNIST.\n",
    "\n",
    "- [ ] Run the following code to download the data.\n",
    "  - The datasets will be saved to the adjacent `downloads` folder\n",
    "  - The pixel data of each image is converted from a Python list to a \"data tensor\" and normalized\n",
    "    - A data tensor is a multi-dimensional array, formatted by PyTorch to support operations on GPUs and other hardware accelerators.\n",
    "    - Tensors are the fundamental data structure in PyTorch and are used to represent inputs, outputs, and parameters of neural networks.\n",
    "  - `trainloader` and `testloader` will be collections representing the respective parts of the dataset.\n",
    "    - Batch size defines how many examples are returned by the loader in every iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./downloads/mnist-train/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:00<00:00, 13444397.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-train/MNIST/raw/train-images-idx3-ubyte.gz to ./downloads/mnist-train/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./downloads/mnist-train/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 396331.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-train/MNIST/raw/train-labels-idx1-ubyte.gz to ./downloads/mnist-train/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./downloads/mnist-train/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 3547429.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-train/MNIST/raw/t10k-images-idx3-ubyte.gz to ./downloads/mnist-train/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./downloads/mnist-train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 1730922.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-train/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./downloads/mnist-train/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./downloads/mnist-test/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:01<00:00, 9470419.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-test/MNIST/raw/train-images-idx3-ubyte.gz to ./downloads/mnist-test/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./downloads/mnist-test/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 362721.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-test/MNIST/raw/train-labels-idx1-ubyte.gz to ./downloads/mnist-test/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./downloads/mnist-test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 3813860.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-test/MNIST/raw/t10k-images-idx3-ubyte.gz to ./downloads/mnist-test/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./downloads/mnist-test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 2407193.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./downloads/mnist-test/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./downloads/mnist-test/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    \"./downloads/mnist-train\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    \"./downloads/mnist-test\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=test_batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Run the following cell to see what a single image looks like as a tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
      "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
      "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
      "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
      "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
      "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
      "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
      "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
      "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
      "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
      "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
      "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
      "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
      "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 5)\n"
     ]
    }
   ],
   "source": [
    "single_image = trainloader.dataset[0]\n",
    "print(single_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log the dataset to Weights and Biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevincorstorphine\u001b[0m (\u001b[33mkevincorstorphine-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/kevincorstorphine/Desktop/mli-2025-05-05-coursework/deep_learning.building_neural_networks/wandb/run-20250507_181534-07zmrj4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kevincorstorphine-self/Hancock/runs/07zmrj4n' target=\"_blank\">Make dataset</a></strong> to <a href='https://wandb.ai/kevincorstorphine-self/Hancock' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kevincorstorphine-self/Hancock' target=\"_blank\">https://wandb.ai/kevincorstorphine-self/Hancock</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kevincorstorphine-self/Hancock/runs/07zmrj4n' target=\"_blank\">https://wandb.ai/kevincorstorphine-self/Hancock/runs/07zmrj4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./downloads/mnist-train)... Done. 0.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./downloads/mnist-test)... Done. 0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Make dataset</strong> at: <a href='https://wandb.ai/kevincorstorphine-self/Hancock/runs/07zmrj4n' target=\"_blank\">https://wandb.ai/kevincorstorphine-self/Hancock/runs/07zmrj4n</a><br> View project at: <a href='https://wandb.ai/kevincorstorphine-self/Hancock' target=\"_blank\">https://wandb.ai/kevincorstorphine-self/Hancock</a><br>Synced 5 W&B file(s), 0 media file(s), 17 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250507_181534-07zmrj4n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Hancock\", name=\"Make dataset\")\n",
    "\n",
    "dataset_artifact = wandb.Artifact(name=\"MNIST\", type=\"dataset\")\n",
    "dataset_artifact.add_dir(\"./downloads/mnist-train\", \"train\")\n",
    "dataset_artifact.add_dir(\"./downloads/mnist-test\", \"test\")\n",
    "wandb.log_artifact(dataset_artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net itself is defined by\n",
    "\n",
    "- The number and types of layers\n",
    "  - 1 input, 1 output, and any number of hidden layers\n",
    "- The size of the input vectors each layer ingests\n",
    "- The size of the output vector each layer produces.\n",
    "\n",
    "![Diagram depicting one linear+non-linear slice of a neural network](./assets/nn-layer-diagram-slide.png)\n",
    "<small> *A linear and non-linear layer in a simple neural network. Source: Neural Network Mechanics lecture.* </small>\n",
    "\n",
    "PyTorch provides the `nn.Sequential` method which sets up the net as a whole, and accepts layer instances as arguments.\n",
    "\n",
    "We will first define each layer individually, and then instantiate `nn.Sequential` with all of them at the end.\n",
    "\n",
    "- [ ] The first layer should be the input layer, instantiated with `nn.Linear()`\n",
    "  - The first argument to `nn.Linear` is the size of the input vector.\n",
    "    - The number of features in the input vector is determined by the size of image. Recall that each image is made up of black-and-white pixels such that each pixel is a brightness value between 0 (black) and 1 (white).\n",
    "    - [ ] How many values would it take to describe a 28√ó28px image?\n",
    "  - The second argument to `nn.Linear` is the length of the vector accepted by the next layer.\n",
    "    - The size of hidden layers is often arbitrary and arrived at by experimentation. In this case, we need to classify an image into 10 classes (the digits 0‚Äì9). The two hidden layers should aim to condense the dimensions from the number of pixels to 10 with each step.\n",
    "    - [ ] Set the second argument to 128 (you should experiment with this later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = nn.Linear(784, 128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "layer_1 = nn.Linear(784, 128)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] The second argument to `nn.Sequential` will be an activation layer, `nn.ReLU()`.\n",
    "  - Activation layers perform a non-linear transform.\n",
    "  - Non-linear activations include Sigmoid, Tanh and ReLU.\n",
    "  - ReLU is a common activation function: `ReLU(x) = max(0, x)` that is proven to produce the following benefits, in addition to introducing non-linearity:\n",
    "    - Mitigates vanishing gradients since the derivative of ReLU for positive values is always 1.\n",
    "    - Promotes sparse activations (only activating a subset of the downstream neurons), leading to more efficient computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "layer_1_activation = nn.ReLU()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] The third and fourth layers should be another linear layer and a non-linear activation layer. \n",
    "  - Make sure the linear layer does more dimensionality reduction, down from the previous linear layer. The goal is to force the model to transform high-dimensional image data (784 dimensions) into a set of probability scores for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2 = nn.Linear(128,64)\n",
    "layer_2_activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "layer_2 = nn.Linear(128, 64)\n",
    "layer_2_activation = nn.ReLU()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] The fifth layer should be the final linear layer:\n",
    "  - [ ] Set the first argument to be the number of activations from the previous layer\n",
    "  - [ ] Set the second argument to be the number of classes we need to produce (the number of possible digits each image represents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_3 = nn.Linear(64,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "layer_3 = nn.Linear(64, 10)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct the model, let's put them all in sequence.\n",
    "\n",
    "- [ ] Provide the layers, in the order that they were created, as individual sequential arguments to `nn.Sequential`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    layer_1,\n",
    "    layer_1_activation,\n",
    "    layer_2,\n",
    "    layer_2_activation,\n",
    "    layer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "model = nn.Sequential(\n",
    "    layer_1,\n",
    "    layer_1_activation,\n",
    "    layer_2,\n",
    "    layer_2_activation,\n",
    "    layer_3\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating and Minimizing Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to setting up a model, we will also need to define how we assess the predictions made by the model.\n",
    "\n",
    "- Our model starts of with randomized weights and biases associated with each node, in each layer of the neural net.\n",
    "- The weights and biases determine the linear transformations that happen to the input data, ultimately producing a predicted class.\n",
    "- Since the model starts with randomized parameters, we need to calculate **loss** ‚Äî¬†the average distance between the predicted class and actual class¬†‚Äî¬†and use it to backpropagate adjustments to the weights and biases in the network.\n",
    "\n",
    "- [ ] Set the `loss_fn` to `nn.CrossEntropyLoss()`\n",
    "  - The term \"cross-entropy\" comes from information theory. In this context, it measures the *dissimilarity* between the predicted probability distribution and the true distribution of the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, we will be using the Adam optimizer (adaptive moment estimation). It changes the \"learning rate\" so that gradient descent slows down as it approaches a loss of 0. We will start with a starting learning rate of 0.003. The value will get updated after every forward pass through the model\n",
    "\n",
    "![Overview of the gradient descent process that minimizes loss over time](./assets/gradient-descent-slide.png)\n",
    "<small> *Overview of the gradient descent process that minimizes loss over time. Source: Neural Network Mechanics lecture.* </small>\n",
    "\n",
    "Adam is a popular choice for optimization but like any hyperparameter, you will need to compare options depending on architecture and budget. Since Adam adjusts the learning rate, it reduces the need for careful tuning of other hyperparameters.\n",
    "  \n",
    "- [ ] Set up your optimization function.\n",
    "  - The first argument should be all the parameters (weights) of the model, available via the `parameters` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Documenting our modeling experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using Weights and Biases to record the inputs and outputs of our modeling experiment.\n",
    "\n",
    "- Because Weights and Biases was designed with deep learning in mind, it has nice built-in support for tracking metrics as we train and test a neural net.\n",
    "- Consequently, the Weights and Biases patterns we use in this notebook will be cleaner and more idiomatic than in our shallow learning notebooks. Keep these patterns in mind for future neural net training!\n",
    "\n",
    "One of the Weights and Biases features we're going to use is the optional `config` argument that we pass to the `init()` function that defines our run. This is a flexible dictionary where you can put useful information that applies to your entire run: typical choices might be\n",
    "\n",
    "- what dataset you're using\n",
    "- your learning rate\n",
    "- The number of epochs you're training for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have initialized a model, selected a loss function, and set up an optimizer we can proceed with training the model on the data.\n",
    "\n",
    "Training will take place in epochs. Each epoch passed the entire dataset through the model once.\n",
    "\n",
    "In order to visualize how the loss decreases over time, we will keep track of the average loss for each epoch in the `losses` list.\n",
    "\n",
    "- [ ] Study the loop below and fill in the missing expressions:\n",
    "  - `predictions` should be the output of the model\n",
    "    - [ ] You can call the model as you would any function and pass images as the argument.\n",
    "  - `loss` should be the output of the loss function defined above\n",
    "    - [ ] Pass the `predictions` and known `labels` as arguments\n",
    "  - The rest of the loop will use the loss to perform backpropagation.\n",
    "- [ ] Run this cell to train your model (this could take a few minutes!)\n",
    "  - Once the cell is executed, you will see a plot of the losses over time.\n",
    "\n",
    "<small>‚è±Ô∏è Expected training time: 1‚Äì5 minutes</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Epoch: 1,\tTraining loss: 0.33013317499683104\n",
      "Epoch: 2,\tTraining loss: 0.17264092950893045\n",
      "Epoch: 3,\tTraining loss: 0.13929856195052995\n",
      "Epoch: 4,\tTraining loss: 0.12144562808810663\n",
      "Epoch: 5,\tTraining loss: 0.10944968808704475\n",
      "Epoch: 6,\tTraining loss: 0.10261825906092437\n",
      "Epoch: 7,\tTraining loss: 0.0942111981440403\n",
      "Epoch: 8,\tTraining loss: 0.08505545745167865\n",
      "Epoch: 9,\tTraining loss: 0.08220773125486845\n",
      "Epoch: 10,\tTraining loss: 0.08072838624308842\n",
      "Epoch: 11,\tTraining loss: 0.07416389039980728\n",
      "Epoch: 12,\tTraining loss: 0.07274210611745509\n",
      "Epoch: 13,\tTraining loss: 0.07273627582286894\n",
      "Epoch: 14,\tTraining loss: 0.06634508541287251\n",
      "Epoch: 15,\tTraining loss: 0.06628433591199057\n",
      "Epoch: 16,\tTraining loss: 0.06155069142453192\n",
      "Epoch: 17,\tTraining loss: 0.06233007875981052\n",
      "Epoch: 18,\tTraining loss: 0.06008996811920284\n",
      "Epoch: 19,\tTraining loss: 0.056903666187444385\n",
      "Epoch: 20,\tTraining loss: 0.05655653222476839\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8I0lEQVR4nO3deXxU5d3///fMJDOTdQIEshFNWBQXIMoSUalWIwFtC61VoH5vlFq1uNz1Tm2VtoLe9r7BpX79qRT6tUW0buh9V21dcImEVg2gLKKAFDDsWUggO8kkM+f3R5IJKUnIJJmcmeT1fDzOg+TMNVc+x8OQt+dc13UshmEYAgAACGJWswsAAAA4HQILAAAIegQWAAAQ9AgsAAAg6BFYAABA0COwAACAoEdgAQAAQY/AAgAAgl6Y2QX0Bq/XqyNHjigmJkYWi8XscgAAQBcYhqGqqiolJyfLau38Gkq/CCxHjhxRamqq2WUAAIBuOHjwoIYPH95pm34RWGJiYiQ1HXBsbKzJ1QAAgK6orKxUamqq7/d4Z/pFYGm5DRQbG0tgAQAgxHRlOAeDbgEAQNAjsAAAgKBHYAEAAEGPwAIAAIIegQUAAAQ9AgsAAAh6BBYAABD0CCwAACDoEVgAAEDQI7AAAICgR2ABAABBj8ACAACCHoGlE1V1Dfrd+7t07/9sk2EYZpcDAMCARWDpRJjVqqc+2qPVnx9UxYkGs8sBAGDAIrB0IsJuU3y0XZJ06PgJk6sBAGDgIrCcRkpchCQCCwAAZiKwnMbwQZGSpMPlBBYAAMxCYDmNlEEtV1hqTa4EAICBi8ByGi23hA5zSwgAANMQWE5jePMVFm4JAQBgHgLLabTeEiKwAABgFgLLabTcEqo40aCqOtZiAQDADASW04hxhssVES6J20IAAJiFwNIFvnEs3BYCAMAUBJYu8M0U4goLAACmILB0AQNvAQAwF4GlC3yr3RJYAAAwBYGlC1qfJ8RqtwAAmIHA0gUsHgcAgLkILF3QElhKq92qa/CYXA0AAAMPgaULXBHhirLbJDHwFgAAMxBYusBisbQOvOW2EAAAfY7A0kWtU5sZeAsAQF8jsHQRq90CAGAeAksXtU5tJrAAANDXCCxdlMLUZgAATENg6SJWuwUAwDwEli5quSVUXFUnd6PX5GoAABhYCCxdFB9tlyPMKsOQCiu4ygIAQF8isHSRxWLhqc0AAJiEwOKHlttCjGMBAKBvEVj80DLw9hAzhQAA6FMEFj8MZ7VbAABMQWDxA6vdAgBgDgKLH1jtFgAAcxBY/NAyhqWosk6NHtZiAQCgr3QrsCxbtkxpaWlyOp3KzMzUxo0bO2z7l7/8RRMnTlRcXJyioqKUkZGhP//5z23aGIahRYsWKSkpSREREcrKytLu3bu7U1pADYtxKNxmkcdrqLiq3uxyAAAYMPwOLKtXr1ZOTo4WL16szZs3a/z48crOzlZJSUm77QcPHqxf//rXys/P17Zt2zR//nzNnz9f7733nq/NI488oieffFIrVqzQhg0bFBUVpezsbNXV1XX/yALAarUoydV8W+gYA28BAOgrFsMwDH/ekJmZqUmTJunpp5+WJHm9XqWmpuquu+7Sfffd16U+LrzwQl1zzTV66KGHZBiGkpOT9fOf/1z33HOPJKmiokIJCQlatWqV5syZc9r+Kisr5XK5VFFRodjYWH8Ox28/ema9Pt1bpsevH68fXDg8oD8LAID+zJ/f335dYXG73dq0aZOysrJaO7BalZWVpfz8/NO+3zAM5ebmateuXfrWt74lSSooKFBRUVGbPl0ulzIzMzvss76+XpWVlW22vsLAWwAA+p5fgaW0tFQej0cJCQlt9ickJKioqKjD91VUVCg6Olp2u13XXHONnnrqKV111VWS5HufP30uWbJELpfLt6WmpvpzGD3CU5sBAOh7fTJLKCYmRlu3btVnn32m//qv/1JOTo7y8vK63d/ChQtVUVHh2w4ePNh7xZ5Gy/OEDrPaLQAAfSbMn8bx8fGy2WwqLi5us7+4uFiJiYkdvs9qtWrUqFGSpIyMDO3cuVNLlizR5Zdf7ntfcXGxkpKS2vSZkZHRbn8Oh0MOh8Of0ntN6y0hBt0CANBX/LrCYrfbNWHCBOXm5vr2eb1e5ebmasqUKV3ux+v1qr6+aVpwenq6EhMT2/RZWVmpDRs2+NVnX2lZ7fZIeZ28Xr/GKwMAgG7y6wqLJOXk5OjGG2/UxIkTNXnyZD3xxBOqqanR/PnzJUnz5s1TSkqKlixZIqlpvMnEiRM1cuRI1dfX65133tGf//xnLV++XJJksVh0991367e//a1Gjx6t9PR03X///UpOTtasWbN670h7SaLLKatFcnu8Olpdr4RYp9klAQDQ7/kdWGbPnq2jR49q0aJFKioqUkZGhtasWeMbNHvgwAFZra0XbmpqanT77bfr0KFDioiI0JgxY/TCCy9o9uzZvja//OUvVVNTo1tvvVXl5eW69NJLtWbNGjmdwRcGwm1WJbkidLj8hA4dP0FgAQCgD/i9Dksw6st1WCTp+hX52rjvmP6/ORmamZES8J8HAEB/FLB1WNCEmUIAAPQtAks3tAy8ZS0WAAD6BoGlG1jtFgCAvkVg6QbfarfcEgIAoE8QWLqhZQzLoeO16gdjlgEACHoElm5IcjVNZa5r8OpYjdvkagAA6P8ILN3gDLdpWEzTowG4LQQAQOARWLqp9bYQgQUAgEAjsHSTb+AtgQUAgIAjsHQTT20GAKDvEFi6aTir3QIA0GcILN3EGBYAAPoOgaWbhsexPD8AAH2FwNJNLVdYquobVXGiweRqAADo3wgs3RRpD9PgKLskBt4CABBoBJYe4KnNAAD0DQJLD7RMbWamEAAAgUVg6YHWtVgILAAABBKBpQe4JQQAQN8gsPRASvPy/IfKGXQLAEAgEVh6gCssAAD0DQJLD7SsxXK8tkE19Y0mVwMAQP9FYOmBWGe4YpxhkpgpBABAIBFYemh48zgWbgsBABA4BJYeap3azMBbAAAChcDSQy0Dbw9xSwgAgIAhsPSQL7BwSwgAgIAhsPQQU5sBAAg8AksPpcQ1D7rllhAAAAFDYOmhlrVYjlbVq67BY3I1AAD0TwSWHhoUGa5Iu02SdISrLAAABASBpYcsFgtPbQYAIMAILL3AN/CWKywAAAQEgaUXpDBTCACAgCKw9IKWmUKsdgsAQGAQWHoBt4QAAAgsAksvSGG1WwAAAorA0gtarrAUV9apweM1uRoAAPofAksviI9yyB5mldeQiirqzC4HAIB+h8DSC6zW1rVYDjLwFgCAXkdg6SU8BBEAgMAhsPQSVrsFACBwCCy9hKnNAAAEDoGll7DaLQAAgUNg6SW+1W7LGXQLAEBvI7D0kpZbQoXldfJ4DZOrAQCgfyGw9JKEWKfCrBY1eg0VV7IWCwAAvYnA0ktsVouS4pySGHgLAEBvI7D0otapzYxjAQCgNxFYetHwQU0Db5kpBABA7yKw9KKWKyzcEgIAoHd1K7AsW7ZMaWlpcjqdyszM1MaNGzts+8wzz2jq1KkaNGiQBg0apKysrFPa33TTTbJYLG226dOnd6c0U7WsxcJqtwAA9C6/A8vq1auVk5OjxYsXa/PmzRo/fryys7NVUlLSbvu8vDzNnTtXa9euVX5+vlJTUzVt2jQdPny4Tbvp06ersLDQt7388svdOyIT8TwhAAACw+/A8vjjj+uWW27R/Pnzde6552rFihWKjIzUypUr223/4osv6vbbb1dGRobGjBmjP/7xj/J6vcrNzW3TzuFwKDEx0bcNGjSoe0dkouG+xeNOyMtaLAAA9Bq/Aovb7damTZuUlZXV2oHVqqysLOXn53epj9raWjU0NGjw4MFt9ufl5WnYsGE6++yztWDBApWVlXXYR319vSorK9tswSDR5ZTVIrkbvSqtqTe7HAAA+g2/Aktpaak8Ho8SEhLa7E9ISFBRUVGX+rj33nuVnJzcJvRMnz5dzz//vHJzc/Xwww9r3bp1mjFjhjweT7t9LFmyRC6Xy7elpqb6cxgBYw+zKiG2eS0WbgsBANBrwvryhy1dulSvvPKK8vLy5HQ6ffvnzJnj+3rs2LEaN26cRo4cqby8PF155ZWn9LNw4ULl5OT4vq+srAya0JISF6HCijodOn5CF5wRere1AAAIRn5dYYmPj5fNZlNxcXGb/cXFxUpMTOz0vY899piWLl2q999/X+PGjeu07YgRIxQfH689e/a0+7rD4VBsbGybLVj4Bt4ytRkAgF7jV2Cx2+2aMGFCmwGzLQNop0yZ0uH7HnnkET300ENas2aNJk6ceNqfc+jQIZWVlSkpKcmf8oJC69RmVrsFAKC3+D1LKCcnR88884yee+457dy5UwsWLFBNTY3mz58vSZo3b54WLlzoa//www/r/vvv18qVK5WWlqaioiIVFRWpurpaklRdXa1f/OIXWr9+vfbt26fc3FzNnDlTo0aNUnZ2di8dZt9htVsAAHqf32NYZs+eraNHj2rRokUqKipSRkaG1qxZ4xuIe+DAAVmtrTlo+fLlcrvd+uEPf9imn8WLF+uBBx6QzWbTtm3b9Nxzz6m8vFzJycmaNm2aHnroITkcjh4eXt9jtVsAAHqfxTCMkF8wpLKyUi6XSxUVFaaPZ9l7tFpX/m6dIu02bX8wWxaLxdR6AAAIVv78/uZZQr2s5QpLrduj8toGk6sBAKB/ILD0Mme4TfHRTbeyeKYQAAC9g8ASAK1Tm5kpBABAbyCwBABPbQYAoHcRWAJgeByBBQCA3kRgCQBWuwUAoHcRWAKAW0IAAPQuAksAtK52y6BbAAB6A4ElAFrWYqmsa1RlHWuxAADQUwSWAIhyhGlQZLgknikEAEBvILAESMs4FgILAAA9R2AJkBTf1GbGsQAA0FMElgDxDbxlajMAAD1GYAmQFBaPAwCg1xBYAoTF4wAA6D0ElgBh0C0AAL2HwBIgw+OaxrCU1bhV6240uRoAAEIbgSVAYiPCFOMIkyQd4bYQAAA9QmAJEIvF4rstdJDbQgAA9AiBJYCGM44FAIBeQWAJoJapzcwUAgCgZwgsAdRyS4i1WAAA6BkCSwD5VrtleX4AAHqEwBJArHYLAEDvILAEUMug25KqetU3ekyuBgCA0EVgCaDBUXY5w5v+ExeW15lcDQAAoYvAEkAWi8U3joXbQgAAdB+BJcBapzYz8BYAgO4isAQYU5sBAOg5AkuAsdotAAA9R2AJMN/UZla7BQCg2wgsAda6eByBBQCA7iKwBFjLLaGiyjo1erwmVwMAQGgisATY0GiH7DarPF5DhRWsxQIAQHcQWALMarUoOc4piac2AwDQXQSWPpDCTCEAAHqEwNIHhsex2i0AAD1BYOkDvissrHYLAEC3EFj6gG8tFq6wAADQLQSWPuBb7ZZBtwAAdAuBpQ+03BI6Un5CXq9hcjUAAIQeAksfSIx1yma1qMFjqKSq3uxyAAAIOQSWPhBmsyoxtmUtFgbeAgDgLwJLH2m5LcTAWwAA/Edg6SPDCSwAAHQbgaWPDGdqMwAA3UZg6SPDBzWtdsvUZgAA/Edg6SOtzxNi0C0AAP4isPSRkxePMwzWYgEAwB8Elj6S5IqQxSLVNXhVVuM2uxwAAEJKtwLLsmXLlJaWJqfTqczMTG3cuLHDts8884ymTp2qQYMGadCgQcrKyjqlvWEYWrRokZKSkhQREaGsrCzt3r27O6UFLXuYVcNiHJIYeAsAgL/8DiyrV69WTk6OFi9erM2bN2v8+PHKzs5WSUlJu+3z8vI0d+5crV27Vvn5+UpNTdW0adN0+PBhX5tHHnlETz75pFasWKENGzYoKipK2dnZqqur6/6RBSHfwFsCCwAAfrEYfg6oyMzM1KRJk/T0009Lkrxer1JTU3XXXXfpvvvuO+37PR6PBg0apKefflrz5s2TYRhKTk7Wz3/+c91zzz2SpIqKCiUkJGjVqlWaM2fOafusrKyUy+VSRUWFYmNj/TmcPvXvL2/RX784ol9dPUa3fmuk2eUAAGAqf35/+3WFxe12a9OmTcrKymrtwGpVVlaW8vPzu9RHbW2tGhoaNHjwYElSQUGBioqK2vTpcrmUmZnZYZ/19fWqrKxss4UCFo8DAKB7/AospaWl8ng8SkhIaLM/ISFBRUVFXerj3nvvVXJysi+gtLzPnz6XLFkil8vl21JTU/05DNO0Tm0msAAA4I8+nSW0dOlSvfLKK3r99dfldDq73c/ChQtVUVHh2w4ePNiLVQZOCqvdAgDQLWH+NI6Pj5fNZlNxcXGb/cXFxUpMTOz0vY899piWLl2qDz/8UOPGjfPtb3lfcXGxkpKS2vSZkZHRbl8Oh0MOh8Of0oPCyavdGoYhi8VickUAAIQGv66w2O12TZgwQbm5ub59Xq9Xubm5mjJlSofve+SRR/TQQw9pzZo1mjhxYpvX0tPTlZiY2KbPyspKbdiwodM+Q1HLFZbq+kZVnmg0uRoAAEKHX1dYJCknJ0c33nijJk6cqMmTJ+uJJ55QTU2N5s+fL0maN2+eUlJStGTJEknSww8/rEWLFumll15SWlqab1xKdHS0oqOjZbFYdPfdd+u3v/2tRo8erfT0dN1///1KTk7WrFmzeu9Ig0CE3ab4aLtKq906eLxWrkiX2SUBABAS/A4ss2fP1tGjR7Vo0SIVFRUpIyNDa9as8Q2aPXDggKzW1gs3y5cvl9vt1g9/+MM2/SxevFgPPPCAJOmXv/ylampqdOutt6q8vFyXXnqp1qxZ06NxLsEqJS5CpdVuHS4/ofNTCCwAAHSF3+uwBKNQWYdFkm5/cZPe+bJI93/nXN18abrZ5QAAYJqArcOCnmO1WwAA/Edg6WOtU5trTa4EAIDQQWDpYy2r3R4u5woLAABdRWDpYykEFgAA/EZg6WMtt4TKaxtUXc9aLAAAdAWBpY/FOMPligiXxMBbAAC6isBiAgbeAgDgHwKLCRh4CwCAfwgsJvANvOWWEAAAXUJgMUHL4nGHCCwAAHQJgcUEvjEs3BICAKBLCCwm8I1hYdAtAABdQmAxQUtgKa12q67BY3I1AAAEPwKLCVwR4Yqy2yQxUwgAgK4gsJjAYrEw8BYAAD8QWEzC1GYAALqOwGISVrsFAKDrCCwmYbVbAAC6jsBiEm4JAQDQdQQWkzDoFgCAriOwmKRlDEtxVZ3cjV6TqwEAILgRWEwSH22XI8wqw5AKK7jKAgBAZwgsJrFYLIxjAQCgiwgsJuIhiAAAdA2BxUQMvAUAoGsILCYazi0hAAC6hMBiopbAsrukSoZhmFwNAADBi8BioolpgxVus2jboQp99HWJ2eUAABC0CCwmSomL0I8vTZckPfTWDtU3ekyuCACA4ERgMdldV4zW0BiH9pXVatUn+8wuBwCAoERgMVm0I0y/zD5bkvTUR3tUUlVnckUAAAQfAksQuPbC4Ro/3KXq+kY9umaX2eUAABB0CCxBwGq1aNF3z5MkvbbpkL44WG5uQQAABBkCS5CYcOYgff+CFEnSg3/bzjRnAABOQmAJIvdOH6NIu02bD5Trza1HzC4HAICgQWAJIokup+749ihJ0pJ3d6qmvtHkigAACA4EliBz86XpSh0coeLKeq1Yt9fscgAACAoEliDjDLfp11efK0n6w9+/0cFjtSZXBACA+QgsQSj7vARdPHKI3I1e/fc7O80uBwAA0xFYgpDFYtGi754rq0V696sifbq31OySAAAwFYElSI1JjNX/uehMSdJ//m2HGj1ekysCAMA8BJYg9h9ZZ8kVEa6vi6r08mcHzS4HAADTEFiC2KAou3KuOkuS9Pj7u1Re6za5IgAAzEFgCXI3ZJ6hsxKidby2QU98uNvscgAAMAWBJciF2axa3PycoT+v369/FleZXBEAAH2PwBICLhkVr+zzEuTxGvrPv+3gOUMAgAGHwBIifn31ubLbrPp4T6k+2FFsdjkAAPQpAkuIOGNIpH4yNV2S9Nu3d6q+0WNyRQAA9B0CSwi549ujNCzGoQPHavWnjwvMLgcAgD5DYAkhUY4w3TdjjCTp6Y/2qLiyzuSKAADoGwSWEDMrI0UZqXGqdXv0yJpdZpcDAECf6FZgWbZsmdLS0uR0OpWZmamNGzd22Hb79u269tprlZaWJovFoieeeOKUNg888IAsFkubbcyYMd0prd+zWi164HtN05z/d/MhbTlw3OSKAAAIPL8Dy+rVq5WTk6PFixdr8+bNGj9+vLKzs1VSUtJu+9raWo0YMUJLly5VYmJih/2ed955Kiws9G0ff/yxv6UNGBmpcbr2wuGSpAf/tkNeL9OcAQD9m9+B5fHHH9ctt9yi+fPn69xzz9WKFSsUGRmplStXttt+0qRJevTRRzVnzhw5HI4O+w0LC1NiYqJvi4+P97e0AeXe6Wcrym7T1oPlemPrYbPLAQAgoPwKLG63W5s2bVJWVlZrB1arsrKylJ+f36NCdu/ereTkZI0YMUI33HCDDhw40GHb+vp6VVZWttkGmmGxTt15xWhJ0tJ3v1Z1faPJFQEAEDh+BZbS0lJ5PB4lJCS02Z+QkKCioqJuF5GZmalVq1ZpzZo1Wr58uQoKCjR16lRVVbW/DP2SJUvkcrl8W2pqard/dij78aVpOnNIpEqq6vX7tXvMLgcAgIAJillCM2bM0HXXXadx48YpOztb77zzjsrLy/Xqq6+2237hwoWqqKjwbQcPHuzjioODI8ym31xzriTpj/8o0IGyWpMrAgAgMPwKLPHx8bLZbCoubrs0fHFxcacDav0VFxens846S3v2tH/VwOFwKDY2ts02UGWdM0xTR8fL7fHqt2/vMLscAAACwq/AYrfbNWHCBOXm5vr2eb1e5ebmasqUKb1WVHV1tfbu3aukpKRe67O/slgsWvSdc2WzWvT+jmJ9vLvU7JIAAOh1ft8SysnJ0TPPPKPnnntOO3fu1IIFC1RTU6P58+dLkubNm6eFCxf62rvdbm3dulVbt26V2+3W4cOHtXXr1jZXT+655x6tW7dO+/bt06effqrvf//7stlsmjt3bi8cYv83OiFG/3bRmZKk/3xruxo9XpMrAgCgd4X5+4bZs2fr6NGjWrRokYqKipSRkaE1a9b4BuIeOHBAVmtrDjpy5IguuOAC3/ePPfaYHnvsMV122WXKy8uTJB06dEhz585VWVmZhg4dqksvvVTr16/X0KFDe3h4A8d/ZJ2lN7ce1j+Lq/XihgO68eI0s0sCAKDXWAzDCPlVxyorK+VyuVRRUTGgx7O8sH6/fvPGV3JFhCvvnss1KMpudkkAAHTIn9/fQTFLCL1j7uQzNCYxRhUnGvT4B/80uxwAAHoNgaUfsVktWvzdpucMvbhhv74uGngL6gEA+icCSz8zZeQQXT02UV5DevCvO9QP7vgBAEBg6Y8WzjhHjjCr8r8p03vbu78CMQAAwYLA0g+lDo7Ubd8aIUn67ds7VdfgMbkiAAB6hsDST/308pFKjHXq0PET+tXrX7I2CwAgpBFY+qlIe5gemnW+bFaL/rL5sG5/cTNXWgAAIYvA0o9ddW6Clt9woexhVr2/o1g3PbtRVXUNZpcFAIDfCCz93LTzEvXc/MmKdoRp/TfH9KNnNqisut7ssgAA8AuBZQCYMnKIXr7lIg2OsuvLwxW6bkW+DpefMLssAAC6jMAyQIwd7tJrP52ilLgIfVNaox8u/1R7SqrMLgsAgC4hsAwgI4dG67WfTtHIoVEqrKjTdSvy9cXBcrPLAgDgtAgsA0xyXIRe++nFGj/cpeO1DfrRM+v1yZ5Ss8sCAKBTBJYBaHCUXS/ecpEuGTVENW6P5j/7mdZ8VWh2WQAAdIjAMkBFO8K08qZJmn5eotwer25/cbNWf3bA7LIAAGgXgWUAc4TZtOyGCzVnUqq8hnTv/36pP6zba3ZZAACcgsAywNmsFi35wVj99LKRkqQl736tJe/u5CnPAICgQmCBLBaL7psxRgtnjJEk/WHdN7rvf3n+EAAgeBBY4HPbZSP1yLXjZLVIqz8/qDtf2sLzhwAAQYHAgjaun5Sq398wQXabVWu2F+nHqz5TdX2j2WUBAAY4AgtOMf38RK2aP0lRdps+3VumHz2zXsdq3GaXBQAYwAgsaNfFo+L10i0XaVBkuLYdqtB1Kz7VEZ4/BAAwCYEFHRqfGqfXfnqxklxO7T3a9PyhvUerzS4LADAAEVjQqVHDovU/Cy7WiKFROtL8/KEvD1WYXRYAYIAhsOC0UuIi9NptUzQ2xaVjNW7NfWa98veWmV0WAGAAIbCgS4ZEO/TyrRdpyoghqq5v1I3PbtR724vMLgsAMEAQWNBl0Y4wPTt/kqadmyB3o1cLXtikVz8/aHZZAIABgMACvzjDbfr9DRfq+onD5TWkX/7PNv37y1tUUlVndmkAgH6MwAK/hdmsevjacbrz26NktUh//eKIrvzdOr2wfr+8Xp5BBADofQQWdIvFYtE92WfrjTsu0dgUl6rqGvWbN77StSs+1c7CSrPLAwD0MwQW9Mi44XF6445LtPi75yraEaYtB8r1nac+1n+/s1O1bpb0BwD0DgILesxmtWj+Jen6MOcyzTg/UR6vof/392901eN/14c7is0uDwDQDxBY0GsSXU4t/z8TtPKmiUqJi9Dh8hP6yfOf67Y/f86y/gCAHiGwoNddMSZBH+R8S7ddNkJhVove216sqx5fpz/+4xs1erxmlwcACEEEFgREpD1MC2eco7f+/VJNOHOQatwe/fbtnZq57BN9cbDc7PIAACGGwIKAGpMYq9dum6IlPxirWGeYth+p1Kzff6JFb36lyroGs8sDAIQIAgsCzmq1aO7kM/TRPZfr+xekyDCk5/P3K+t36/TWtiMyDNZuAQB0jsCCPhMf7dD/nZ2hF3+SqfT4KJVU1evOl7bopmc/04GyWrPLAwAEMQIL+twlo+L17s+m6mdXjpbdZtW6fx7VVf93nZat3SN3I4NyAQCnIrDAFM5wm/7jqrP07t1TNWXEENU3evXoe7t0zZP/0Gf7jpldHgAgyBBYYKqRQ6P10i2Zevz68RoSZdfukmpdtyJf9/7PNh2vcZtdHgAgSBBYYDqLxaIfXDhcuT+/THMmpUqSVn9+UFc+vk7P5+9TeS3BBQAGOovRD6ZoVFZWyuVyqaKiQrGxsWaXgx76fN8x/fr1r7SruEqSFG6z6PKzh2lmRrKyzkmQM9xmcoUAgN7gz+9vAguCUoPHqxfW79fqzw7q66Iq3/5oR5imnZegWRkpunjkEIXZuEgIAKGKwIJ+ZVdRld7celhvbj2iwyc9kyg+2qHvjEvSzIxkZaTGyWKxmFglAMBfBBb0S4ZhaNP+43pz6xG9/WWhjp00KDdtSKS+l5GimRnJGjk02sQqAQBdRWBBv9fg8erj3aV6Y+thvb+9WCcaPL7Xxqa4NDMjWd8dn6yEWKeJVQIAOkNgwYBS627UBzuK9ebWI/r7P4+q0dv0V9pikaaMGKJZGSnKPj9RrohwkysFAJyMwIIB61iNW29/Wag3txzW5/uP+/bbw6y6onmm0bfHDGOmEQAEAQILIOngsVr99YsjenPrYf2zuNq3P8YRpunnJ2rWBSm6aMQQ2awM1gUAM/jz+7tbc0KXLVumtLQ0OZ1OZWZmauPGjR223b59u6699lqlpaXJYrHoiSee6HGfQFekDo7UHd8epff/4zK9+7Op+ullI5XscqqqvlGvbTqkG/64Qd9+LE9/+rhAVXUNZpcLAOiE34Fl9erVysnJ0eLFi7V582aNHz9e2dnZKikpabd9bW2tRowYoaVLlyoxMbFX+gT8dU5SrO6bMUYf33uFXr1tin6UeYZcEeE6cKxWD721Qxf9d64e+Ot27SutMbtUAEA7/L4llJmZqUmTJunpp5+WJHm9XqWmpuquu+7Sfffd1+l709LSdPfdd+vuu+/utT4lbgmhe064PXp9y2E9+0mBdpc03TKyWKQrzh6mH1+arotHDmFtFwAIoIDdEnK73dq0aZOysrJaO7BalZWVpfz8/G4V250+6+vrVVlZ2WYD/BVht+lHmWfo/f/4lv5882RdMWaYDEPK/bpEN/xxg6Y/8Q+9vPGA6k6aMg0AMIdfgaW0tFQej0cJCQlt9ickJKioqKhbBXSnzyVLlsjlcvm21NTUbv1sQGp6+OLU0UO18qZJ+ujnl+nGKWcq0m7TruIqLfzLl5qyJFePrPlahRUnTt8ZACAgQvJBLAsXLlRFRYVvO3jwoNkloZ8YMTRaD848X/kLr9RvrjlHwwdF6Hhtg36ft1dTH16ru17eos0Hjp++IwBArwrzp3F8fLxsNpuKi4vb7C8uLu5wQG0g+nQ4HHI4HN36eUBXuCLC9ZOpIzT/knR9uLNYKz8u0IaCY/rbF0f0ty+OaHxqnH58SZquHpukcB7ACAAB59e/tHa7XRMmTFBubq5vn9frVW5urqZMmdKtAgLRJ9BbbFaLss9L1Orbpujtf79UP5wwXHabVV8cLNfPXtmqSx/+SE9/tLvNc40AAL3PrysskpSTk6Mbb7xREydO1OTJk/XEE0+opqZG8+fPlyTNmzdPKSkpWrJkiaSmQbU7duzwfX348GFt3bpV0dHRGjVqVJf6BILBeckuPXbdeN03Y4xe2nBAf16/X8WV9Xrs/X/qqY/2aFZGiuZfmqYxicxUA4De1q2Vbp9++mk9+uijKioqUkZGhp588kllZmZKki6//HKlpaVp1apVkqR9+/YpPT39lD4uu+wy5eXldanP02FaM8zgbvTq7S+PaOXH+/Tl4Qrf/otHDtH8S9J1xZhhrKILAJ1gaX6gDxmGoU37j+vZT/bp3a8K1fzsRZ05JFI/mTpC100YzrOLAKAdBBbAJIfLT+j5/H16ZeNBVZxoWu5/aIxDN1+arhsyz1CMkydGA0ALAgtgslp3o1797KD+39+/0ZGKOklSrDNMN16cppsuTtOQaGa5AQCBBQgS7kav3tx6WCvW7dXeo03PKXKGWzVn0hm69VsjlBwXYXKFAGAeAgsQZLxeQ+/vKNKytXt9A3TDrBZ9/4IU/fTykRo5NNrkCgGg7xFYgCBlGIY+3lOq36/dq/xvyiQ1PXBxxvmJuv3yUTo/xWVyhQDQdwgsQAjYfOC4fr92rz7c2brK89TR8brj26OUmT6YJ0UD6PcILEAI2VVUpeV5e/S3bYXyNM+JvvCMON1++ShdMWaYrKzlAqCfIrAAIejgsVr94e979ernh+Ru9EqSzk6I0e3fHqlrxiYpjGcWAehnCCxACCupqtOfPi7Qi+sPqLq+UZJ0xuBI3fqtEfohi9AB6EcILEA/UFHboOfz9+nZT/f5Hq44NMahn1yarhsuOlPRDr8fBQYAQYXAAvQjte5Grf7soJ75l0XofjghVWOSYjQiPkrp8VEaHGVnoC6AkEJgAfohd6NXbzQvQvdN8yJ0J4txhvnCS1rznyPio5UWH8kjAQAEJQIL0I95vIY+2FGkT/aUqaC0RgWlNTpScUKdfZLjox2nhpmhUTpjcCRjYgCYhsACDDB1DR7tL6tVQWm1Ckpb/qxRQWmtSqvrO3yfxSIluyI0YmhTiGkJNCPio5TocsoRRpgBEDgEFgA+lXUN2td8JaZl21dao2+O1qiqeRZSR6LsNsVF2jU4yq5BUXYNigzXoEi7BkXaNTgqvHlf8xbV9BpXbAB0lT+/v5lmAPRzsc5wjRsep3HD49rsNwxDZTXuNkGm4GiN9pU1fV3f6FWN26Ma9wkdLj/R5Z8XEW5rDjit4WZQ5EnhJsquIVF2ZaTGKYqZTgC6iH8tgAHKYrEoPtqh+GiHJqUNbvOa12uoqr5Rx2vcOlbrVnmtW8dqGpr/dOt4rVvHaxp0rNat4zVuHa9t0PFatzxeQycaPDpcfvqQ4wy36ooxw/Sdccn69tnDFGHnygyAjnFLCECvMIyTQk6NW+W1Da3hpjnwHG/+/tDxtoEm0m5T1jkJ+s64JH3rrKHcVgIGCMawAAhqhmFo+5FK/W3bEb31RWGb8BLjCNNV5yXou+OSdcmoeNnDeCQB0F8RWACEDMMwtPVgud7aVqi3txWqqLLO95orIlzTz0vUNeOSdPHIITxPCehnCCwAQpLXa2jTgeN664sjevvLojZTsgdH2TX9/ER9Z1ySMtOHyMZTrIGQR2ABEPI8XkMbCsr01rZCrfmqyPc8JanpmUpXn5+o74xP1oQzBslKeAFCEoEFQL/S6PHq071lemvbEa35qkiVda3rxyS5nLp6bJK+My5JGalxPE8JCCEEFgD9lrvRq4/3HNVbXxTq/R3Fqj5p8bvhgyJ0zbgkTTs3UclxThayA4IcgQXAgFDX4NHf/3lUb20r1Ic7i1Xr9pzSxhlu1aBIu1wR4b4VeeMiW1ftPXV/0z7GyACBR2ABMOCccHu0dleJ3tp2RBsLjqu81q1Gb/f+ebNYmlYIjotsG27imv+M9HORO39uU1kknZ0Yo8z0wcyKQr9HYAEw4BmGoer6RpU3r8J7vLZppd6W7zvaX1XX+fOV+srgKLuyz0vQ1WOTdNGIIQonvKAfIrAAQDc1eLyqONEUYo7XNq3OW37S9+W1bp1o59ZTR/z9B9bd6NX6b8p0vLbBt29QZLimnZuoq5vXoyG8oL8gsABACGv0eLX+m2N6+8tCvbe97ZRuV0S4pp2boKvHJemSkawEjNBGYAGAfqLR49XGgtbwUlrdGl5inWG66txEXTMuUZeMipcjjBlRCC0EFgDohzxeQxsLjumdLwv17ldtVwKOcYbpqnOaxrxcOjqe6dwICQQWAOjnPF5Dn+9rDS8lVa3hJdoRpqxzhunqsTz9GsGNwAIAA0jLM5jebn6MwckPkIyy23Rl85WXy88mvCC4EFgAYIDyeg1tOXhcb28r0rtfFaqwojW8RNptuuysoRoSbZdFTWvDWCxNa7+cvFZM0z6L7zXfPkvzu5p3ntym5e1RjjBNOGOQxqfGEY5wWgQWAIC8XkNbD5XrnW1Nt40Ol5/os59tD7MqIzVOF6UPVuaIIbrgjDhF2sP67OcjNBBYAABtGIahLw5V6JM9pXI3epv2Nb0go+kPGc2rxjR93XaffPsMGa27fG1a9h2tqteGgmNtBgRLUpjVonHDXcocMUSZ6YM14cxBinGGB/ioEewILAAA0xiGoYLSGm0oOKYN35RpQ8GxNremJMlqkc5PcSkzfbAmpw/R5LTBckUSYAYaAgsAIGgYhqFDx09o/Tdl2lhwTBsKjunAsdo2bSwWaUxirDLTBzeHmMEaEu0wqWL0FQILACCoFVac0MaCY1r/zTFtKCjTN0drTmkzeli0JjePgbkofbCGxTo77dPrNVTX6NEJt0e1bo/qGjw60dD09YkGj+rcJ3190v4TJ7WNiwhXUlyEkuMilBLnVJIrQsNiHDyIMkAILACAkFJSVafPCo5rQ0GZNnxzTLuKq05pkzYkUqmDI9sEkTp369f1zWNzepvNalFirFNJLqeSm8NMcpxTya7Wr10R4X49lRtNCCwAgJB2rMatz/Yd04bmKzA7Civlz28rZ7hVEeG2ps3evIXbFGEPU0S4VZH2MDmbX49sft0RZtWxGrcKK+p0uPyEjpSfUFFFnRq9p//BkXabkuMilORyKqU51Jz8daLLyTTvdhBYAAD9SsWJBm3af0zHahp8AcMXNsJtcp4UPJxhNlmtvXO1w+M1VFpd7wswheWtYeZIRdP3ZSc9nLIz8dEOjRwapdEJ0Ro9LMb3Z3y0fcBenSGwAADQR+oaPE1h5qQrM//6fV1Dx7er4iLDNXpYtEYnxDT92RxmhsU4+n2QIbAAABAkDMNQeW2DDh6v1e7iau0uqdaekirtLqnWgWO1Hd7qinWG+ULMqGHROiuhKcgkxjr7TZAhsAAAEALqGjzaU1KtPSXV2l1Spd3FTV/vK6tRR0Nnoh1hzQGm6WrMqIRojR4WrWRXRK/dCusrBBYAAEJYXYNHBaU1TVdjipuuxuwuqda+0poOBwFbLVKYzaowq6Vpa/463GaVzWpRmK15v9WqcJuleZ+1Tdt22ze/ZrdZ9ZvvnNurx+nP728e7AAAQJBxhtt0TlKszklq+0vc3ejVvrKa5ltLVc2BplrflFarwWPI3ehV14YA+88e1vuBxR8EFgAAQoQ9zKqzEmJ0VkKMpCTf/gaPV8dr3GrwGvJ4DDV4vWr0GGo85c/mzeNVg8eQx9u2Tcu+Bo+3+bXWr82+2URgAQAgxIXbrKddCTjUsdYwAAAIet0KLMuWLVNaWpqcTqcyMzO1cePGTtu/9tprGjNmjJxOp8aOHat33nmnzes33XSTLBZLm2369OndKQ0AAPRDfgeW1atXKycnR4sXL9bmzZs1fvx4ZWdnq6SkpN32n376qebOnaubb75ZW7Zs0axZszRr1ix99dVXbdpNnz5dhYWFvu3ll1/u3hEBAIB+x+9pzZmZmZo0aZKefvppSZLX61Vqaqruuusu3Xfffae0nz17tmpqavTWW2/59l100UXKyMjQihUrJDVdYSkvL9cbb7zRrYNgWjMAAKHHn9/ffl1hcbvd2rRpk7Kyslo7sFqVlZWl/Pz8dt+Tn5/fpr0kZWdnn9I+Ly9Pw4YN09lnn60FCxaorKzMn9IAAEA/5tcsodLSUnk8HiUkJLTZn5CQoK+//rrd9xQVFbXbvqioyPf99OnT9YMf/EDp6enau3evfvWrX2nGjBnKz8+XzXbq0y3r6+tVX1/v+76ystKfwwAAACEmKKY1z5kzx/f12LFjNW7cOI0cOVJ5eXm68sorT2m/ZMkSPfjgg31ZIgAAMJFft4Ti4+Nls9lUXFzcZn9xcbESExPbfU9iYqJf7SVpxIgRio+P1549e9p9feHChaqoqPBtBw8e9OcwAABAiPErsNjtdk2YMEG5ubm+fV6vV7m5uZoyZUq775kyZUqb9pL0wQcfdNhekg4dOqSysjIlJSW1+7rD4VBsbGybDQAA9F9+T2vOycnRM888o+eee047d+7UggULVFNTo/nz50uS5s2bp4ULF/ra/+xnP9OaNWv0u9/9Tl9//bUeeOABff7557rzzjslSdXV1frFL36h9evXa9++fcrNzdXMmTM1atQoZWdn99JhAgCAUOb3GJbZs2fr6NGjWrRokYqKipSRkaE1a9b4BtYeOHBAVmtrDrr44ov10ksv6Te/+Y1+9atfafTo0XrjjTd0/vnnS5JsNpu2bdum5557TuXl5UpOTta0adP00EMPyeFw9NJhAgCAUOb3OizBiHVYAAAIPQFbhwUAAMAMQTGtuadaLhKxHgsAAKGj5fd2V2729IvAUlVVJUlKTU01uRIAAOCvqqoquVyuTtv0izEsXq9XR44cUUxMjCwWS6/2XVlZqdTUVB08eLDfj48ZSMcqDazj5Vj7r4F0vBxr/2MYhqqqqpScnNxmwk57+sUVFqvVquHDhwf0Zwyk9V4G0rFKA+t4Odb+ayAdL8fav5zuykoLBt0CAICgR2ABAABBj8ByGg6HQ4sXLx4Qi9gNpGOVBtbxcqz910A6Xo51YOsXg24BAED/xhUWAAAQ9AgsAAAg6BFYAABA0COwAACAoEdgkbRs2TKlpaXJ6XQqMzNTGzdu7LT9a6+9pjFjxsjpdGrs2LF65513+qjS7luyZIkmTZqkmJgYDRs2TLNmzdKuXbs6fc+qVatksVjabE6ns48q7pkHHnjglNrHjBnT6XtC8bxKUlpa2inHarFYdMcdd7TbPtTO69///nd997vfVXJysiwWi9544402rxuGoUWLFikpKUkRERHKysrS7t27T9uvv5/7vtDZsTY0NOjee+/V2LFjFRUVpeTkZM2bN09HjhzptM/ufBb6wunO60033XRK3dOnTz9tv8F4XqXTH297n2GLxaJHH320wz6D9dwGyoAPLKtXr1ZOTo4WL16szZs3a/z48crOzlZJSUm77T/99FPNnTtXN998s7Zs2aJZs2Zp1qxZ+uqrr/q4cv+sW7dOd9xxh9avX68PPvhADQ0NmjZtmmpqajp9X2xsrAoLC33b/v37+6jinjvvvPPa1P7xxx932DZUz6skffbZZ22O84MPPpAkXXfddR2+J5TOa01NjcaPH69ly5a1+/ojjzyiJ598UitWrNCGDRsUFRWl7Oxs1dXVddinv5/7vtLZsdbW1mrz5s26//77tXnzZv3lL3/Rrl279L3vfe+0/frzWegrpzuvkjR9+vQ2db/88sud9hms51U6/fGefJyFhYVauXKlLBaLrr322k77DcZzGzDGADd58mTjjjvu8H3v8XiM5ORkY8mSJe22v/76641rrrmmzb7MzEzjtttuC2idva2kpMSQZKxbt67DNs8++6zhcrn6rqhetHjxYmP8+PFdbt9fzqthGMbPfvYzY+TIkYbX62339VA+r5KM119/3fe91+s1EhMTjUcffdS3r7y83HA4HMbLL7/cYT/+fu7N8K/H2p6NGzcakoz9+/d32Mbfz4IZ2jvWG2+80Zg5c6Zf/YTCeTWMrp3bmTNnGldccUWnbULh3PamAX2Fxe12a9OmTcrKyvLts1qtysrKUn5+frvvyc/Pb9NekrKzsztsH6wqKiokSYMHD+60XXV1tc4880ylpqZq5syZ2r59e1+U1yt2796t5ORkjRgxQjfccIMOHDjQYdv+cl7dbrdeeOEF/fjHP+70QaChfF5PVlBQoKKiojbnzuVyKTMzs8Nz153PfbCqqKiQxWJRXFxcp+38+SwEk7y8PA0bNkxnn322FixYoLKysg7b9qfzWlxcrLfffls333zzaduG6rntjgEdWEpLS+XxeJSQkNBmf0JCgoqKitp9T1FRkV/tg5HX69Xdd9+tSy65ROeff36H7c4++2ytXLlSb775pl544QV5vV5dfPHFOnToUB9W2z2ZmZlatWqV1qxZo+XLl6ugoEBTp05VVVVVu+37w3mVpDfeeEPl5eW66aabOmwTyuf1X7WcH3/OXXc+98Gorq5O9957r+bOndvpw/H8/SwEi+nTp+v5559Xbm6uHn74Ya1bt04zZsyQx+Npt31/Oa+S9NxzzykmJkY/+MEPOm0Xque2u/rF05rhnzvuuENfffXVae91TpkyRVOmTPF9f/HFF+ucc87RH/7wBz300EOBLrNHZsyY4ft63LhxyszM1JlnnqlXX321S//XEqr+9Kc/acaMGUpOTu6wTSifVzRpaGjQ9ddfL8MwtHz58k7bhupnYc6cOb6vx44dq3HjxmnkyJHKy8vTlVdeaWJlgbdy5UrdcMMNpx0MH6rntrsG9BWW+Ph42Ww2FRcXt9lfXFysxMTEdt+TmJjoV/tgc+edd+qtt97S2rVrNXz4cL/eGx4ergsuuEB79uwJUHWBExcXp7POOqvD2kP9vErS/v379eGHH+onP/mJX+8L5fPacn78OXfd+dwHk5awsn//fn3wwQedXl1pz+k+C8FqxIgRio+P77DuUD+vLf7xj39o165dfn+OpdA9t101oAOL3W7XhAkTlJub69vn9XqVm5vb5v9ATzZlypQ27SXpgw8+6LB9sDAMQ3feeadef/11ffTRR0pPT/e7D4/Hoy+//FJJSUkBqDCwqqurtXfv3g5rD9XzerJnn31Ww4YN0zXXXOPX+0L5vKanpysxMbHNuausrNSGDRs6PHfd+dwHi5awsnv3bn344YcaMmSI332c7rMQrA4dOqSysrIO6w7l83qyP/3pT5owYYLGjx/v93tD9dx2mdmjfs32yiuvGA6Hw1i1apWxY8cO49ZbbzXi4uKMoqIiwzAM49/+7d+M++67z9f+k08+McLCwozHHnvM2Llzp7F48WIjPDzc+PLLL806hC5ZsGCB4XK5jLy8PKOwsNC31dbW+tr867E++OCDxnvvvWfs3bvX2LRpkzFnzhzD6XQa27dvN+MQ/PLzn//cyMvLMwoKCoxPPvnEyMrKMuLj442SkhLDMPrPeW3h8XiMM844w7j33ntPeS3Uz2tVVZWxZcsWY8uWLYYk4/HHHze2bNnimxmzdOlSIy4uznjzzTeNbdu2GTNnzjTS09ONEydO+Pq44oorjKeeesr3/ek+92bp7Fjdbrfxve99zxg+fLixdevWNp/j+vp6Xx//eqyn+yyYpbNjraqqMu655x4jPz/fKCgoMD788EPjwgsvNEaPHm3U1dX5+giV82oYp/97bBiGUVFRYURGRhrLly9vt49QObeBMuADi2EYxlNPPWWcccYZht1uNyZPnmysX7/e99pll11m3HjjjW3av/rqq8ZZZ51l2O1247zzzjPefvvtPq7Yf5La3Z599llfm3891rvvvtv33yUhIcG4+uqrjc2bN/d98d0we/ZsIykpybDb7UZKSooxe/ZsY8+ePb7X+8t5bfHee+8Zkoxdu3ad8lqon9e1a9e2+3e35Zi8Xq9x//33GwkJCYbD4TCuvPLKU/47nHnmmcbixYvb7Ovsc2+Wzo61oKCgw8/x2rVrfX3867Ge7rNgls6Otba21pg2bZoxdOhQIzw83DjzzDONW2655ZTgESrn1TBO//fYMAzjD3/4gxEREWGUl5e320eonNtAsRiGYQT0Eg4AAEAPDegxLAAAIDQQWAAAQNAjsAAAgKBHYAEAAEGPwAIAAIIegQUAAAQ9AgsAAAh6BBYAABD0CCwAACDoEVgAAEDQI7AAAICgR2ABAABB7/8H+IXX6n6YEkwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Capture the losses over time for plotting\n",
    "losses = []\n",
    "# Number of training epochs to perform\n",
    "epochs = 20\n",
    "\n",
    "# Initialize a new run to capture this train/test cycle\n",
    "run = wandb.init(\n",
    "    project=\"Hancock\",\n",
    "    name=\"First Hancock Model\",\n",
    "    config={\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"learning_rate\": 0.003,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Indicate that we'll use the MNIST training and test sets created above\n",
    "run.use_artifact(\"MNIST:latest\")\n",
    "\n",
    "# Set the device to run on: GPU, MPS, or CPU\n",
    "device = torch.device(\n",
    "    \"cpu\")\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "print(f\"Using {device} device\")\n",
    "model = model.to(device)\n",
    "\n",
    "for e in range(epochs):\n",
    "    total_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784-dimensional vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # Convert input to device\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward-propagation through the model to get predictions\n",
    "        predictions = model(images)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(predictions, labels)\n",
    "\n",
    "        # Log the loss to Weights and Biases\n",
    "        wandb.log({\"training_loss\": loss})\n",
    "\n",
    "        # Reset the _gradients_ for all of the model parameters\n",
    "        # so that only the current batch is used to update them.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the learning rate\n",
    "        optimizer.step()\n",
    "\n",
    "        # Capture the loss for this batch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_loss = total_loss / len(trainloader)\n",
    "    print(f\"Epoch: {e+1},\\tTraining loss: {epoch_loss}\")\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "for e in range(epochs):\n",
    "    total_loss = 0\n",
    "    i = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784-dimensional vector\n",
    "        images = images.view(images.shape[0], -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward-propagation through the model to get predictions\n",
    "        predictions = model(images)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(predictions, labels)\n",
    "\n",
    "        #...\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have designed and trained a neural network from scratch.\n",
    "\n",
    "- Note how the losses decreased with each epoch but we reached a point of diminishing returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the performance of our trained model is a crucial step, and the reason we set aside 14% of the dataset in `testloader`\n",
    "\n",
    "- The following code runs inside of a `torch.no_grad` block, which will turn of gradient calculations (unnecessary during inference) to save memory.\n",
    "- [ ] Note that use of `torch.max()`\n",
    "  - We are telling PyTorch to find the maximum value in the outputs tensor, along its first dimension\n",
    "  - However, we are not interested in the value itself (`_`) as it will just be some probability value\n",
    "  - We are interested in the _index_ of the max value, `predicted`, which will tell us which digit is in the input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 2, Actual: 2\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 7, Actual: 7\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 6, Actual: 6\n",
      "Predicted: 9, Actual: 9\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 9, Actual: 9\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 9, Actual: 9\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # Temporarily turn off gradient calculation for prediction\n",
    "    # images will be a collection containing a single image\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.view(images.shape[0], -1).to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        print(f\"Predicted: {predicted[0]}, Actual: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cell above is run, we can see a collection of 10 guesses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's end with a full inference run across the entire test set. We will use this to generate an accuracy score.\n",
    "\n",
    "- [ ] Copy the code above into the following cell, and edit it to remove the break after 10 images.\n",
    "- [ ] Initialize a variable, `correct_count`, to count the number of correct guesses.\n",
    "- [ ] Instead of printing values, update `correct_count` based on whether the prediction matched the label.\n",
    "- [ ] Compute and print a variable `accuracy` which can be computed as a percentage of correct guess, divided by `len(testloader)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/bcl7bj6n2fqf9j03fdhyl02c0000gn/T/ipykernel_81543/3428332228.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predicted_prob = nn.functional.softmax(outputs)[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.17356687898089%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.view(images.shape[0], -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Use softmax function to get predicted probability from outputs\n",
    "        predicted_prob = nn.functional.softmax(outputs)[\n",
    "            range(outputs.shape[0]), predicted\n",
    "        ]\n",
    "\n",
    "        # compute the accuracy of the model\n",
    "        correct += (predicted == labels.to(device)).sum().item() / labels.shape[0]\n",
    "\n",
    "        # add test example to test_preds_table\n",
    "        # Initialize wandb table for test predictions if not already done\n",
    "        if not hasattr(wandb, 'test_preds_table'):\n",
    "            wandb.test_preds_table = wandb.Table(columns=[\"id\", \"predicted_prob\", \"predicted\", \"actual\"])\n",
    "        \n",
    "        # Add data to the table\n",
    "        # Add data to wandb table with explanation of softmax outputs:\n",
    "        # predicted_prob[0] is the probability (0-1) of the predicted class after softmax\n",
    "        # softmax converts raw model outputs (logits) into probabilities that sum to 1\n",
    "        # higher probability means model is more confident in its prediction\n",
    "        \n",
    "        wandb.test_preds_table.add_data(\n",
    "            i, predicted_prob[0].item(), predicted[0].item(), labels[0].item()\n",
    "        )\n",
    "\n",
    "    accuracy = correct / len(testloader)\n",
    "    print(f\"Accuracy: {accuracy*100}%\")\n",
    "    wandb.log({\"test_accuracy\": accuracy})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution:</summary>\n",
    "\n",
    "```py\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.view(images.shape[0], -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Use softmax function to get predicted probability from outputs\n",
    "        predicted_prob = nn.functional.softmax(outputs)[\n",
    "            range(outputs.shape[0]), predicted\n",
    "        ]\n",
    "\n",
    "        # compute the accuracy of the model\n",
    "        correct += (predicted == labels.to(device)).sum().item() / labels.shape[0]\n",
    "\n",
    "        # add test example to test_preds_table\n",
    "        test_preds_table.add_data(\n",
    "            i, predicted_prob, predicted[0], labels[0]\n",
    "        )\n",
    "\n",
    "    accuracy = correct / len(testloader)\n",
    "    print(f\"Accuracy: {accuracy*100}%\")\n",
    "    wandb.log({\"test_accuracy\": accuracy})\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an accuracy of around 96.64%.\n",
    "\n",
    "- [ ] Change the number of training epochs to 1 and re-run the cells above to retrain and retest your models. What effect does it have?\n",
    "  - [ ] Try 25 epochs\n",
    "  - Remember, too many epochs can have diminishing returns or even overfit your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the model and Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, let's export it for use elsewhere e.g. a digit-guessing app's server.\n",
    "\n",
    "- [ ] Run the cell below to save the model to the specified path\n",
    "- [ ] [Optional] Write a Python script to load the model and perform inference for a given image.\n",
    "  - [Relevant PyTorch docs](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>training_loss</td><td>‚ñà‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.97174</td></tr><tr><td>training_loss</td><td>0.04912</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">First Hancock Model</strong> at: <a href='https://wandb.ai/kevincorstorphine-self/Hancock/runs/xt7ocnsr' target=\"_blank\">https://wandb.ai/kevincorstorphine-self/Hancock/runs/xt7ocnsr</a><br> View project at: <a href='https://wandb.ai/kevincorstorphine-self/Hancock' target=\"_blank\">https://wandb.ai/kevincorstorphine-self/Hancock</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250507_203243-xt7ocnsr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model, \"./downloads/mnist.pth\")\n",
    "\n",
    "# save to Weights nad Biases\n",
    "model_artifact = wandb.Artifact(name=\"MNIST_classifier\", type=\"model\")\n",
    "model_artifact.add_file(\"./downloads/mnist.pth\")\n",
    "run.log_artifact(model_artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö¶ Checkpoint: Stop\n",
    "\n",
    "- [ ] Uncomment this code\n",
    "- [ ] Complete the feedback form\n",
    "- [ ] Run the cell to log your responses and record your stop time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deep_atlas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdeep_atlas\u001b[49m.log_feedback(\n\u001b[32m      2\u001b[39m     {\n\u001b[32m      3\u001b[39m         \u001b[38;5;66;03m# How long were you actively focused on this section? (HH:MM)\u001b[39;00m\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mactive_time\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mThis section was an ENORMOUS pain in the ass for me to do because my version in python didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have the nz? package? Jesus helped me out, but we had to uninstall and reinstall python to fix it.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m         \u001b[38;5;66;03m# Did you feel finished with this section (Yes/No):\u001b[39;00m\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfinished\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m         \u001b[38;5;66;03m# How much did you enjoy this section? (1‚Äì5)\u001b[39;00m\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33menjoyment\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m,\n\u001b[32m      9\u001b[39m         \u001b[38;5;66;03m# How useful was this section? (1‚Äì5)\u001b[39;00m\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musefulness\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m,\n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m# Did you skip any steps?\u001b[39;00m\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mskipped_steps\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m# Any obvious opportunities for improvement?\u001b[39;00m\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msuggestions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhelp other people not deal with the same dependecy error\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     }\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'deep_atlas' is not defined"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_feedback(\n",
    "    {\n",
    "        # How long were you actively focused on this section? (HH:MM)\n",
    "        \"active_time\": \"This section was an ENORMOUS pain in the ass for me to do because my version in python didn't have the nz? package? Jesus helped me out, but we had to uninstall and reinstall python to fix it.\",\n",
    "        # Did you feel finished with this section (Yes/No):\n",
    "        \"finished\": \"yes\",\n",
    "        # How much did you enjoy this section? (1‚Äì5)\n",
    "        \"enjoyment\": 3,\n",
    "        # How useful was this section? (1‚Äì5)\n",
    "        \"usefulness\": 5,\n",
    "        # Did you skip any steps?\n",
    "        \"skipped_steps\": \"no\",\n",
    "        # Any obvious opportunities for improvement?\n",
    "        \"suggestions\": \"help other people not deal with the same dependecy error\",\n",
    "    }\n",
    ")\n",
    "deep_atlas.log_stop_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You did it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we explored how to load a dataset, set up a Deep Neural Network model in PyTorch, train and validate the model parameters and export it for use elsewhere.\n",
    "\n",
    "PyTorch offers many APIs for customizing the structure or a model, some of which we will explore in the future. You may even come across and prefer versions of its API for Class-based definitions or APIs that support functional programming. Whichever API you choose, the concepts covered in this exercise will be relevant:\n",
    "\n",
    "- Sourcing and splitting training and testing data\n",
    "- Choosing layer types\n",
    "- Choosing a loss function\n",
    "- Running forward and backpropagation to train parameters\n",
    "- Saving and loading models for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [PyTorch: nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "- [List of PyTorch's Activation Layer Types](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- [List of PyTorch's Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "  - [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mli-2025-05-05-coursework-rNXVWyyx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
