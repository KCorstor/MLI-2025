{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives\n",
    ">\n",
    "> 1. Understand the hierarchy of options when tuning LLM-driven systems\n",
    "\n",
    "> Estimated time required: 1h:15m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Watch [Maximizing LLM Performance](https://youtu.be/ahnGLM-RC1Y?t=83) (45m run time) by engineers from OpenAI, where they will orient you around some of the major options for effective use of any API, or even models running on your own infrastructure.\n",
    "\n",
    "> Note: You don't need to understand every technical detail of how to do the things they're talking about; this assignment is only intended to show you what options exist and how those options relate to each other. For that reason, we think you'll only need to pause and rewind a little a bit.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
